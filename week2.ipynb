"""
    TO BE USED IN A JUPYTER NOTEBOOK
"""


import numpy
import torch
import math
import pandas
import matplotlib
from sagemaker import get_execution_role
from torch.autograd import Variable
from torch.nn import MSELoss
from torch.optim import SGD
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler


def import_csv_file_from_bucket(fileName):
    role = get_execution_role()
    bucket = 'morkalork'
    data_location = 's3://{}/data/{}'.format(bucket, fileName)
    return pandas.read_csv(data_location)


class PyTorchLRModel(torch.nn.Module):
    def __init__(self, input_dimension, output_dimension):
        super(PyTorchLRModel, self).__init__()
        self.linear = torch.nn.Linear(input_dimension, output_dimension)

    def forward(self, x):
        out = self.linear(x)
        return out


def pytorch_lr_fit(x, y, learning_rate, epochs, lambda1, lambda2):
    input_dimensions = x.ndim
    output_dimensions = y.ndim

    if input_dimensions == 1:
        x = x[:, numpy.newaxis]
    else:
        input_dimensions = x.shape[1]

    if output_dimensions == 1:
        y = y[:, numpy.newaxis]
    else:
        output_dimensions = y.shape[1]

    model = PyTorchLRModel(input_dimensions, output_dimensions)
    criterion = MSELoss()
    optimiser = SGD(model.parameters(), lr=learning_rate, weight_decay=lambda2)
    losses = []

    for epoch in range(epochs):
        epoch += 1

        features = Variable(torch.from_numpy(x).float(), requires_grad=True)
        response = Variable(torch.from_numpy(y).float())

        optimiser.zero_grad()
        predictions = model.forward(features)
        loss = criterion(predictions, response)

        if lambda1 > 0.0:
            params = torch.cat([x.view(-1) for x in model.linear.parameters()])
            l1_regularization = lambda1 * torch.norm(params, 1)
            loss += l1_regularization

        loss.backward()
        optimiser.step()

        losses.append(loss.data.item())

    return model, losses


def train():
    training_data = import_csv_file_from_bucket('training.csv');
    columns = ['bmi', 'map', 'ldl', 'hdl', 'tch', 'glu', 'ltg', 'y']
    number_of_features = len(columns[0:-1])

    scaler = MinMaxScaler()
    train_data = scaler.fit_transform(training_data[columns])

    model, losses = pytorch_lr_fit(
        numpy.array(train_data[:, 0:number_of_features]),
        numpy.array(train_data[:, number_of_features]),
        0.1,
        1000,
        0.0,
        0.0
    )

    raw_test_data = import_csv_file_from_bucket('test.csv')
    test_data = scaler.transform(raw_test_data[columns])

    test_input = Variable(torch.from_numpy(test_data[:, 0:number_of_features]).float())

    predictions = model(test_input)

    rmse = math.sqrt(mean_squared_error(predictions.data.numpy(), test_data[:, number_of_features]))

    print('RMSE without regularization: %0.4f' % rmse)

    loss_data_frame = pandas.DataFrame(losses, columns=['loss'])
    loss_data_frame.plot(logy=True)


train()

def crazy_train():
    training_data = import_csv_file_from_bucket('training.csv');
    columns = ['bmi', 'map', 'ldl', 'hdl', 'tch', 'glu', 'ltg', 'y']
    number_of_features = len(columns[0:-1])

    scaler = MinMaxScaler()
    train_data = scaler.fit_transform(training_data[columns])

    model, losses = pytorch_lr_fit(
        numpy.array(train_data[:, 0:number_of_features]),
        numpy.array(train_data[:, number_of_features]),
        0.1,
        1000,
        0.0,
        0.0
    )

    raw_test_data = import_csv_file_from_bucket('test.csv')
    test_data = scaler.transform(raw_test_data[columns])
    
    test_input = Variable(torch.from_numpy(test_data[:, 0:number_of_features]).float())
    rates = numpy.linspace(0.0005,0.02,100)

    metrics = []
    for rate in rates:
        model, _ = pytorch_lr_fit(numpy.array(train_data[:, 0:number_of_features]),
                                       numpy.array(train_data[:, number_of_features]), 0.1, 1000, 0.0, rate)

        predictions = model(test_input)
        rmse = math.sqrt(mean_squared_error(predictions.data.numpy(),
                                            test_data[:, number_of_features]))
        metrics.append(rmse)
    
    l2_df = pandas.DataFrame(metrics, columns=['RMSE'])
    l2_df['l2 reg. rate'] = rates
    l2_df.set_index('l2 reg. rate').plot()

crazy_train()