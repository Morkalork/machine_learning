!pip install msgpack
!pip install onnxmltools
!pip install lightgbm

import pandas

import matplotlib.pyplot as pyplot
import numpy
import torch
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from torch.autograd import Variable
from sagemaker import get_execution_role
from onnxmltools import convert_sklearn
from onnxmltools.convert.common.data_types import FloatTensorType
import onnxmltools


def import_csv_file_from_bucket(fileName):
    role = get_execution_role()
    bucket = 'morkalork'
    data_location = 's3://{}/data/{}'.format(bucket, fileName)
    return pandas.read_csv(data_location)


def logistic(x):
    return 1 / (1 + numpy.exp(-x))


def basic_logistic_regression():
    x = numpy.arange(-6, 6, 0.001)
    y = logistic(x)

    pyplot.plot(x, y)
    pyplot.xlabel('x')
    pyplot.ylabel('logistic(x)')
    pyplot.show()


def pre_process(data_frame, threshold):
    """
    The data looks like this:
        FICO.Range,Interest.Rate
        735-739,2.90%
        ...

    :param data_frame: A data frame containing the CSV-data
    :param threshold: I have no fucking clue
    :return: The processed data
    """
    data_frame['class'] = data_frame['Interest.Rate'].apply(
        lambda rate: 1.0 if float(rate.replace('%', '')) <= threshold else 0.0
    )

    data_frame['fico_score'] = data_frame['FICO.Range'].apply(
        lambda range: float(range.split('-')[0])
    )

    data_frame['fico_score'] = data_frame['fico_score'].apply(
        lambda lowest: (lowest - data_frame['fico_score'].min()) / (
                data_frame['fico_score'].max() - data_frame['fico_score'].min())
    )

    return data_frame[['fico_score', 'class']]


class LogRegModel(torch.nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LogRegModel, self).__init__()
        self.linear = torch.nn.Linear(input_dim, output_dim)

    def forward(self, x):
        out = torch.sigmoid(self.linear(x))
        return out


def logistic_regression_fit(x, y, learning_rate, epochs):
    input_dimension = x.ndim
    output_dimension = y.ndim

    if input_dimension == 1:
        x = x[:, numpy.newaxis]
    else:
        input_dimension = x.shape[1]

    if output_dimension == 1:
        y = y[:, numpy.newaxis]
    else:
        output_dimension = y.shape[1]

    model = LogRegModel(input_dimension, output_dimension)
    criterion = torch.nn.BCELoss()
    optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)

    for epoch in range(epochs):
        epoch += 1

        features = Variable(torch.from_numpy(x).float())
        labels = Variable(torch.from_numpy(y).float())

        optimiser.zero_grad()

        predictions = model.forward(features)
        loss = criterion(predictions, labels)

        loss.backward()
        optimiser.step()

    return model


def store_model_as_onnyx(model, input):
    torch.onnx.export(
        model,
        input,
        'exports/loan_data.onnx',
        verbose=True
    )


def logistic_regression():
    training_data = import_csv_file_from_bucket('loan_data.csv');
    data_frame = pre_process(training_data, 12.0)

    train, test = train_test_split(data_frame, test_size=0.2)
    model = logistic_regression_fit(
        train['fico_score'].values,
        train['class'].values,
        0.1,
        10000
    )

    data_input = Variable(
        torch.from_numpy(
            test['fico_score'].values[:, numpy.newaxis]).float()
    )

    store_model_as_onnyx(model, data_input)
    print('Saved loan data model')

    raw_predictions = model(data_input)
    predictions = []
    for prediction in raw_predictions:
        if prediction.data.numpy()[0] > 0.50:
            predictions.append(1.0)
        else:
            predictions.append(0.0)

    acc = accuracy_score(test['class'].values, predictions)
    print('Accuracy: ', acc)


def another_attempt_at_logistic_regression():
    training_data = import_csv_file_from_bucket('grad_school.csv');

    X = training_data[['gre', 'gpa', 'rank']]
    X = MinMaxScaler().fit_transform(X)
    data_scaled = pandas.DataFrame(X, columns=['gre', 'gpa', 'rank']).join(training_data['admit'])

    train, test = train_test_split(data_scaled, test_size=0.2)

    train.head()

    model = logistic_regression_fit(train[['gre', 'gpa', 'rank']].values, train['admit'].values, 0.1, 10000)

    raw_predictions = model(Variable(torch.from_numpy(test[['gre', 'gpa', 'rank']].values).float()))
    predictions = []
    for prediction in raw_predictions:
        if prediction.data.numpy()[0] > 0.50:
            predictions.append(1.0)
        else:
            predictions.append(0.0)

    acc = accuracy_score(test['admit'].values, predictions)
    print('Accuracy: ', acc)

    dummy_input = Variable(torch.from_numpy(test[['gre', 'gpa', 'rank']].values).float())
    torch.onnx.export(model, dummy_input, "exports/log_reg.onnx")
    print('Saved random forest model')


def main():
    logistic_regression()
    another_attempt_at_logistic_regression()

